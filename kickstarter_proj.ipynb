{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter project (need to spell check)\n",
    "## Our project for this semester is to try and predict whether a fundraising campaign in kickstarter will succeed or not.\n",
    "\n",
    "This type of prediction can actualy be useful in several scenarios, whether for an entrepreneur trying to evaluate his chances, the kickstarter company itself that would like to promote promising campaigns or for an investor considering backing a company.\n",
    "\n",
    "There are a few datasets available in kaggle such as: [here](https://www.kaggle.com/codename007/funding-successful-projects) and [here](https://www.kaggle.com/kemical/kickstarter-projects). These datasets are more limited timespan wise and in their richness of data. The dataset that we used in our project is offered [here](https://webrobots.io/kickstarter-datasets/). It is very large and somewhat messy, so our first steps are going to be devoted to get to know this dataset and clean it up so we can use it easily.\n",
    "\n",
    "The data is scraped over different periods, the last scrape is from Nov 2019 and contains 57 very large csv files. Our first step would be to unify it all (scrapes from 2015 onwards, each containing about 100,000 records, with a lot of overlaping) into a single dataframe, and explore the columns.\n",
    "Due to size limitations, we added an extra step here, and removed duplicates and live projects (which are about 10% of the data, but are usless). Otherwise, the built data frame might be to big to fit into memory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kickstarter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # some seaborn plots ommit warnings. Known issue.\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step will auto download the cleaned dataset as a pickle and extract it. It is also possible to build the dataset yourself with passing the argument cache=None, but this is a lengthy process that might take a few hours (downloading about 50 generations of the dataset, each about 1GB and uniting them). Once this pickle is on your computer, it will be auto loaded from it's location.\n",
    "\n",
    "### note that this step requires internet connectivity and will download up to 1.5GB of data to your computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter import data_loader as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dl.make_dataframe(path=r'rawData') #Files are assumed to be located in rawData sub.dir. caches pickle in cwd.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Let's get a few details about this data: What are the features, how many records exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns.values)\n",
    "print(pd.Series(cols))\n",
    "num_recs = len(df.index)\n",
    "print('There are originaly {} records in data'.format(num_recs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a first peek at the data via Excel hints that there are many empty columns:\n",
    "![peek](img/firstPeek.png)\n",
    "\n",
    "Let's see what columns contain mostly null values:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nes = df.isna().sum()\n",
    "nes.sort_values(ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not missing anything too important so far (though some sound important they are either not used or interchangable with other fields that are kept). Off with their head!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = {'friends','is_backing','is_starred','is_starrable','permissions', 'source_url'\n",
    "         ,'country_displayable_name','converted_pledged_amount','current_currency',\n",
    "         'usd_type','fx_rate', 'has_more','last_update_published_at','projects','search_url',\n",
    "         'seed','staff_pick','total_hits','unread_messages_count','unseen_activity_count'}\n",
    "letgo = [name for name in empty if name in cols] # For rerun\n",
    "df.drop(columns=letgo,inplace=True)\n",
    "nes = df.isna().sum()\n",
    "nes.sort_values(ascending=False, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing redundant columns\n",
    "We can already see redundant attributes which we are sure we will not need:\n",
    "- Data that is used for display purpases: such as 'currency_symbol', 'currency_trailing_code'.\n",
    "- Data that is biased: such as backers count (This is part of the prediction), or disable_communication which is an option for failed projects \n",
    "- Data that will not be used by our model: location, 'profile', 'urls','usd_type', 'location'.\n",
    "Let's start with dropping these.\n",
    "\n",
    "Looks like we can drop 'friends','is_backing','is_starred','permissions' as they are basicaly empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redundant = {'backers_count','currency_symbol', 'currency_trailing_code','disable_communication',\n",
    "             'profile','urls','spotlight','usd_pledged'}\n",
    "letgo = [name for name in redundant if name in cols]\n",
    "df.drop(columns=letgo, inplace=True)\n",
    "cols = list(df.columns.values)\n",
    "print(pd.Series(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">TODO: insert baseline model here</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter import feature_extraction as fe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting dates\n",
    "From looking at the data we can also see that the time fields are given in UNIX time. It'll be usefull ahead if we can break each date into a day month year trio. We'll run the conversion and replace each column with the corresponding 3 fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timefields = ['created_at','deadline','launched_at','state_changed_at']\n",
    "fe.convert_time(df,timefields)\n",
    "df[timefields].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another inconviniency in this dataset is that some of the fields are given in json form, specificaly the 'catagory' and 'creator' attributs. We'll parse just the interesting parts out of these fields and remove all bloat text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.extract_catagories(df) #gets project catagory data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing that remains is to convert the goal amount which is the project's local currency (and not usd).\n",
    "Once this is done we no longer need the static usd column (it is dropped by the function). We will also parse the project photo url for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.convert_goal(df)\n",
    "fe.get_image_url(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool. Looks like our data is relativly balanced, and projects in our data set are almost eaqualy likely to fail or succeed. Now let's take a look at the creator column. This is a jason field that is (as usual with this dataset) filled with illegal json strings, we'll fix it and extract the creator id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.extract_creator_id(df) #replaces the creator json with creator id int, un\n",
    "df[[\"creator_id\", \"creator\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values that we did not fix, got a creator id of -1. Let's see if there are many of these, and if not we'll just drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baddies = df.loc[df['creator_id'] == -1]\n",
    "print('Number of bad projects dropped due to irregular creator field: {}'.format(len(baddies)))\n",
    "df.drop(baddies.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this field for some more good and extract the user's profile picture and whether she \\ he is a registered kickstarter user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.extract_creator_fields(df)\n",
    "print(df['creator_status'].value_counts())\n",
    "print(df['super_creator'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, the information about the users is missing. We'll drop these two new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df.columns.values)\n",
    "bad = {'creator_status','super_creator'}\n",
    "letgo = [name for name in bad if name in cols]\n",
    "df.drop(columns=letgo,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter import visio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at how our data distributes globaly.\n",
    "projects by origin country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_by_country(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring our dataset, we could see that this column is actualy corrupted, where projects from different locations are labled as American or British projects. We'll use another field, 'location' to fix this data. The location information is contained in jason form, and we will parse relevant fields. Where location is NAN, we'll stay with the original contry column. Let's fix this and see how many projects actually come from each country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.extract_country(df)\n",
    "counts = df['country'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While being more acurate, we also added a lot of noise to our dataset. We will define a threshold, any country with less projects than the threshold will be changed to be considered 'Global'. This will help us keeping are data from being too sparse, and will also save us from satistical errors or biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimun number of samples to appear in dataset\n",
    "thresh = 450\n",
    "fe.unify_countries(df, counts, thresh)\n",
    "counts = df['country'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this more accurate and compact global partition breaks down to success vs. failure rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_by_country(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to estimate the rest of the world as it's shadowed by the US. Let's check out all countries but the US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_by_country(df.loc[df['country'] != 'US'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As US is the major origin country, Let's use data available to us in JSON form to extract the origin state within the US. This data is noisy: some projects in the US contain nan as state field, or some straight-out garbage arabic words and such. This is a small minority of US projects, so we will just mark all of these as 'US unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.get_us_state(df)\n",
    "counts = df['country'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final breakdown by country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_by_country(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that while most states and countries destribute close to the original distribution, some locations break out: projects from California, New-York or Great Britan (GB) have a larger chance to succeed, while projects from Florida or Texas and several other southern states tend to fail. We extracted all we could from the location column, and can now drop it and move forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['location'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how catagory effects success rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_by_category(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems as product catagory has an impact on campaign result. Our data set allows us to view this in even finer granularity, by sub catagories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_by_sub_category(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing to factor in is seasonality, let's see if there is any change in the success depending on project start month. To be able to look at this data over several years, we'll add specific month and year columns for launched_at and deadline. We will also add a field calculating the delta in months between launch and deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.extract_month_and_year(df, ['launched_at','deadline'])\n",
    "fe.add_destination_delta_in_days(df)\n",
    "visio.plot_success_by_launched_month(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, looking at the whole period of given data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_over_time(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the duration of the campaign affects the probability of success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_success_by_destination_delta_in_days(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = df.loc[df['goal']<30000]\n",
    "sns.distplot(inner['goal']).set(xlim=(0))\n",
    "print('number of records out of range:',len(df.loc[df['goal']>30000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = df.loc[df['goal']>30000]\n",
    "inner = inner.loc[df['goal']<200000]\n",
    "sns.distplot(inner['goal']).set(xlim=(0))\n",
    "#print('number of records out of range:',len(df.loc[df['goal']<50000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = df.loc[df['goal']<80000]\n",
    "sns.distplot(inner['goal']).set(xlim=(0))\n",
    "print('number of records out of range:',len(df.loc[df['goal']>80000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cent = df.loc[df['goal']<30000]\n",
    "cent.plot.scatter(x='goal',y='pledged')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next we want to gather statistics about each creator's previous projects  \n",
    "### But first!\n",
    "In order to prevent leakage lets split the dataframe into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter.data import Data\n",
    "data = Data(df) # Some container for the train,test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somthing that might be interesting to learn, is how well this creator's past projects did. The function called bellow, extracts per creator the total number of past projects by him/her, the number of successful ones and the number of un-succesful ones (contains failed projects, cancled etc - this field will be delt with next)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from kickstarter.transformers import CreatorTransformer\n",
    "\n",
    "data.apply_transformer(CreatorTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter.visio import plot_sccess_by_creator_history\n",
    "plot_sccess_by_creator_history(data.train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finished extracting all the data contained in the creator column. We can now drop it and move on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_df.drop(columns=['creator'],inplace=True)\n",
    "data.test_df.drop(columns=['creator'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is basicaly what we are asking, let's see how many projects of each status are in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_distriubtion_by_state_slice(data.train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since live projects can't be used, we'll clear them out and also unite suspended and canceled project to be labled as failed.\n",
    "We waited until applying this step, as we wanted to count canceled or suspended projects as a part of our creators history. This reduction, gives us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe.fix_state(data) #deletes live projects and unites failed.\n",
    "print(data.train_df[\"state\"].value_counts())\n",
    "visio.plot_distriubtion_by_state_slice(data.train_df)\n",
    "num_recs = len(data.train_df)\n",
    "print('After processing there are {} records in train data'.format(num_recs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Let's try running a few naive models and see what it is that we are dealing with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import knn_model as knn\n",
    "import logistic_regression_model as logistic\n",
    "import random_forest_model as forest\n",
    "import gradient_boosting_model as gradient_boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_pr = logistic.run_model(data)\n",
    "models = {'Logistic regression' : logReg_pr}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few other models: KNN, Random forest and gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pr = knn.run_model(data)\n",
    "models['KNN'] = knn_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pr = forest.run_model(data)\n",
    "models['Random forest'] = forest_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pr = gradient_boosting.run_model(data)\n",
    "models['Gradient boost'] = boost_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_precision(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! So up until now we used standard techniques. Now we will try and leverage the most interesting data we have in out set. The free text fields (which are the project's name, and 'blurb' which is a short discription of the project), and the projects pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pickled_data/before_nima.pickle\", \"wb\") as pickle_file:\n",
    "    pickle.dump(data, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Project photos\n",
    "The first thing we need to do to be able to gain some insights from the images is to be able to access them. We took a step in that direction, when parsing the urls for images in the dataset. Now the more chalenging part was to actualy obtain them. We chose to download them (as opposed to accessing them directly online or some other 'lazy' approach), as we predicted we would want to try a few different models on them and this would save us time on the long run. For this purpose (and to actualy run the models), we used a dedicated Azure cloud VM to download the 314K pictures weighing about 30GB. This enabled us to run uninterupted and with faster connection. The whole downloading process took about 2 days (with the very naive and un-paralelised code bellow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter import nima\n",
    "import inspect\n",
    "lines = inspect.getsource(nima.download_photos)\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we had the photos we needed to find what we can do with them (actualy we did the reaserch before opening a dedicated VM and dowloading, but this narrates better). \n",
    "\n",
    "Doing some reaserch, we found NIMA, a paper by google's AI team, that suggest's leveraging convolutional neural networks to predict how aesthetically pleasing a photograph is.\n",
    "\n",
    "https://arxiv.org/pdf/1709.05424.pdf\n",
    "\n",
    "This seemed like a novel feature and we decided to find an implementation of the model on-line, as no model was actualy released by google. We tried a few private repos on git-hub, which did not seem promising (running them on a small sub-sample gave results that did not sit well with our judgment of the photos).\n",
    "\n",
    "Finaly, we found a project by Idealo (a German e-commerce site, sort of like 'zap.co.il') which implements NIMA and was already succesfully used to rate hotels by on-line pictures.\n",
    "\n",
    "Leveraging the model on our dataset required some tweeking and learning, especially in the data loading phase, where the original input for the model was different than ours and so where the pictures formats). This was also quite chalenging as running the model was only possible using a docker container we needed to learn how to handle.\n",
    "\n",
    "Running the model on all 314K pictures with our GPU clad VM took several hours and yielded two jason arrays with the results. We can now add them into the dataset. As this is a lengthy process (due to the unfriendly output of the model) you can uncomment the cell bellow which will automatically download the clean dataset panda as a pickle and load it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dl.get_pickles('with_NIMA.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if you want to add nima manually\n",
    "# from kickstarter.transformers import NimaTransformer\n",
    "# \n",
    "# data.apply_transformer(NimaTransformer())\n",
    "# \n",
    "# with open(\"pickled_data/with_NIMA.pickle\", \"wb\") as pickle_file:\n",
    "#     pickle.dump(data, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nes = data.df.isna().sum()\n",
    "print(nes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_df.dropna(subset=['nima_score','nima_tech'], inplace=True)\n",
    "data.test_df.dropna(subset=['nima_score','nima_tech'], inplace=True)\n",
    "len(data.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sense of what this model returned. We'll display bellow 9 random rhigh scoring images and 9 random low scoring ones. This function retreives these photos on-line, so it requires internet access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.display_imgs(data.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the distribution of the technical ratings and the aesthetical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.df[['nima_score']], hist=False, rug=False, axlabel = 'Image score', label = 'aesthetic score')\n",
    "sns.distplot(data.df[['nima_tech']], hist=False, rug=False, label = 'Technical score').set_title('Image score distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = data.df.loc[data.df['state'] == 'successful']\n",
    "losers = data.df.loc[data.df['state'] == 'failed']\n",
    "sns.distplot(losers[['nima_score']], hist=False, rug=False, axlabel = 'Image score', label = 'failed projects')\n",
    "sns.distplot(winners[['nima_score']], hist=False, rug=False, label = 'successful projects').set_title('Image score distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(losers[['nima_tech']], hist=False, rug=False, axlabel = 'Image score', label = 'failed projects')\n",
    "sns.distplot(winners[['nima_tech']], hist=False, rug=False, label = 'successful projects').set_title('Image technical score distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the aesthetical model seems to be the one holding the most potential twards differentiating the distributions of the failed and successful projects, we will focus on it. Let's extract the distributions paramaters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mean = data.df.nima_score.mean()\n",
    "print('nima score total mean is {}'.format(total_mean))\n",
    "total_std = data.df.nima_score.std()\n",
    "print('nima score total std is {}'.format(total_std))\n",
    "winner_mean = winners.nima_score.mean()\n",
    "print('winners nima score mean is {}'.format(winner_mean))\n",
    "winner_std = winners.nima_score.std()\n",
    "print('winners nima score std is {}'.format(winner_std))\n",
    "loser_mean = losers.nima_score.mean()\n",
    "print('losers nime score mean is {}'.format(loser_mean))\n",
    "loser_std = losers.nima_score.std()\n",
    "print('losers nima score std is {}'.format(loser_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare general distribution to normal distribution with same mean and std\n",
    "sns.distplot(data.df[['nima_score']], hist=False, rug=False, axlabel = 'Image score', label = 'total aesthetic score')\n",
    "norm = np.random.normal(total_mean,total_std,300000)\n",
    "sns.distplot(norm, hist=False, rug=False, axlabel = 'Image score', label = 'normal distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare successful distribution to normal distribution with same mean and std\n",
    "sns.distplot(winners[['nima_score']], hist=False, rug=False, label = 'successful projects').set_title('Image score distribution')\n",
    "norm = np.random.normal(winner_mean,winner_std,300000)\n",
    "sns.distplot(norm, hist=False, rug=False, axlabel = 'Image score', label = 'normal distribution \\n with succ. params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare failed distribution to normal distribution with same mean and std\n",
    "sns.distplot(losers[['nima_score']], hist=False, rug=False, axlabel = 'Image score', label = 'failed projects')\n",
    "norm = np.random.normal(loser_mean,loser_std,300000)\n",
    "sns.distplot(norm, hist=False, rug=False, axlabel = 'Image score', label = 'normal distribution \\n with failed params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is no ampirical normality test, but we can see that these distributions are practicaly normal, as is expected by the specification of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_pr = logistic.run_model(data, nima = True)\n",
    "models['Logistic regression with nima'] = logReg_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pr = knn.run_model(data, 40, nima = True)\n",
    "models['KNN with NIMA'] = knn_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pr = forest.run_model(data, nima = True)\n",
    "models['Random forest with nima'] = forest_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pr = gradient_boosting.run_model(data, nima = True)\n",
    "models['Gradient boost with nima'] = boost_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visio.plot_precision(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 6: Project text attributes\n",
    "Looking at NLP attributes of projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter import nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nes = data.df.isna().sum()\n",
    "print(nes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_df.dropna(subset=['blurb','name'], inplace=True)\n",
    "data.test_df.dropna(subset=['blurb','name'], inplace=True)\n",
    "len(data.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter.transformers import SemanticTransformer\n",
    "data.apply_transformer(SemanticTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.df[[\"blurb\", \"blurb_pos\", \"blurb_neg\", \"blurb_compound\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.df[['blurb_pos']], hist=False, rug=False, axlabel = 'dist', label = 'Positivness score')\n",
    "sns.distplot(data.df[['blurb_compound']], hist=False, rug=False, axlabel = 'dist', label = 'Compoundness')\n",
    "sns.distplot(data.df[['blurb_neg']], hist=False, rug=False, label = 'neg score').set_title('Image score distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logReg_pr = logistic.run_model(data, ['launched_at_month', 'launched_at_year', 'category', 'parent_category', 'destination_delta_in_days', 'goal', 'nima_score','blurb_pos','blurb_neg', 'blurb_compound'])\n",
    "models = {'Logistic regression' : logReg_pr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pr = knn.run_model(df, 20 , input_fields = ['launched_at_month', 'launched_at_year', 'category', 'parent_category', 'destination_delta_in_days', 'goal', 'nima_score','blurb_pos','blurb_neg', 'blurb_compound'])\n",
    "models['KNN'] = knn_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pr = forest.run_model(df, 950, ['launched_at_month', 'launched_at_year', 'category', 'parent_category', 'destination_delta_in_days', 'goal', 'nima_score','blurb_pos','blurb_neg', 'blurb_compound'])\n",
    "models['Random forest'] = forest_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_pr = gradient_boosting.run_model(df, 1000, ['launched_at_month', 'launched_at_year', 'category', 'parent_category', 'destination_delta_in_days', 'goal', 'nima_score','blurb_pos','blurb_neg', 'blurb_compound'])\n",
    "models['Gradient boost'] = boost_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 7: Adding one hot encoding\n",
    "So far, even though we have shown (by plots) the importance of \"country\", we haven't trained on this categorical data.\n",
    "Moreover, we treated \"category\" and \"parent_category\" as ordinal data, instead of treating it as one hot encoding, and by doing so, we may have created unwanted proximity between values that are not necessarily similar.\n",
    "Hence, we will try to train on those as one hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter.transformers import OneHotTransformer\n",
    "data.apply_transformer(OneHotTransformer())\n",
    "data.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 8: Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter.transformers import BagOfWords\n",
    "data.apply_transformer(BagOfWords())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 9: TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kickstarter.transformers import TfidfTransformer\n",
    "data.apply_transformer(TfidfTransformer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given our final representation for our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_fields = ['launched_at_month', 'launched_at_year', 'destination_delta_in_days', 'goal', 'nima_score','blurb_pos','blurb_neg', 'blurb_compound',\"bag_of_words\"]\n",
    "input_fields.extend([col for col in data.df.columns if str.startswith(col, 'category_name_')])\n",
    "input_fields.extend([col for col in data.df.columns if str.startswith(col, 'parent_category_name_')])\n",
    "input_fields.extend([col for col in data.df.columns if str.startswith(col, 'country_')])\n",
    "input_fields.extend([col for col in data.df.columns if str.startswith(col, 'tfidf_')])\n",
    "input_fields.append(\"nima_tech\")\n",
    "len(input_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: WIP delete this\n",
    "data.input_fields = input_fields\n",
    "assert set(data.train_x.columns) == set(input_fields)\n",
    "# data.train_y = data.le.transform(data.train_df[\"state\"])\n",
    "# data.test_y = data.le.transform(data.test_df[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: WIP delete this\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data.train_x)\n",
    "\n",
    "X_train = data.train_x\n",
    "X_test = data.test_x\n",
    "y_train = data.train_y\n",
    "y_test = data.test_y\n",
    "\n",
    "forest = LGBMClassifier()\n",
    "forest.fit(X_train, y_train)\n",
    "pred = forest.predict_proba(X_test)\n",
    "\n",
    "print('precision is: ' + str(1 - np.mean(pred != y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: WIP delete this\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import svm\n",
    "\n",
    "C = [10**i for i in range(-2,3)]\n",
    "gamma = [10**i for i in range(-7,8)]\n",
    "parameters = {'kernel':['linear', 'rbf'], 'C':C, 'gamma' : gamma}\n",
    "\n",
    "cols = list(df.columns.values)\n",
    "fields = [field for field in input_fields if field in cols]\n",
    "X = df[fields]\n",
    "y = df['state']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.best_params_)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
